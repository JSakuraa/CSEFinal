{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "!ls D:\\DevProjects\\CSEFinal\\ProjectFiles\\asl_alphabet_train\\asl_alphabet_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "train_data = \"asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "splitfolders.ratio(train_data, output=\"datasets/asl_alphabet\", \n",
    "                   seed=1337, ratio=(.8,.1,.1), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'datasets/asl_alphabet/train'\n",
    "val_dir = 'datasets/asl_alphabet/val'\n",
    "test_dir  = 'datasets/asl_alphabet/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c956dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (32, 32)\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Grayscale conversion\n",
    "    transforms.Resize(target_size),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders with shuffling for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create data loader for testing (no shuffling needed)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcb89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = list(train_dataset.class_to_idx.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fd89b",
   "metadata": {},
   "source": [
    "## Show dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1233a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "TRAIN_PATH = train_data\n",
    "\n",
    "def sample_img(labels):\n",
    "    \n",
    "    y_val = 12\n",
    "    num_label = len(labels)\n",
    "    if(num_label < 10):\n",
    "        y_size = y_size * num_label / 10\n",
    "    fig, axs = plt.subplots(num_label, 9, figsize = (y_val, 13))\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        axs[i, 0].text(0.5,0.5, label, ha='center', va='center', fontsize=10)\n",
    "        axs[i, 0].axis('off')\n",
    "        \n",
    "        label_path = os.path.join(TRAIN_PATH, label)\n",
    "        list_files = os.listdir(label_path)\n",
    "        \n",
    "        for j in range(8):\n",
    "            img_label = cv.imread(os.path.join(label_path, list_files[j]))\n",
    "            img_label = cv.cvtColor(img_label, cv.COLOR_BGR2RGB)\n",
    "            axs[i, j+1].imshow(img_label)\n",
    "            axs[i, j+1].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Sample images from data\", x=0.55, y=0.92)\n",
    "    \n",
    "    plt.show()\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144c8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_img(labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696c660",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)\n",
    "in_shape = (32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = models.Sequential()\n",
    "# 1st convolution layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=in_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# 2nd convolution layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd convolution layer\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# fully-connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60656ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
